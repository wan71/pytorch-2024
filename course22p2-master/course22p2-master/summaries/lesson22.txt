Alright, hi gang, and here we are in lesson 21 and joined by the legends themselves, Johno and Tanishq. Hello. Hello. And today you'll be shocked to see here that we are going to look at a Jupyter Notebook. Amazing, right? We're going to look at Notebook 22. This is a pretty quick. Just, you know, improvement, pretty simple improvement, to our DDPM slash DDIM implementation for fashion, and this is all the same so far that what I've done is I've made some quite significant change, and some of the changes we'll be making today are all about making life simpler. And they're kind of reflecting the way the papers have been taking things, and it's interesting to see how the papers have not only made things better, it made things simpler. And so what of the things that I've noticed in recent papers is that there's no longer a concept of N steps, which is something we've always had before, and it always bothered me a bit this capital T thing. You know, this T over T, it's basically saying this is time step number say 500 out of 1000, so it's time step 0.5. Why don't just call it 0.5. And the answer is, well, we can. So we talked last time about the cosine scheduler. We didn't end up using it because I came up with an idea which was, you know, simpler. And nearly the same, just to change our beta max. But in this next, don't want to say, let's use the cosine scheduler, but let's try to get rid of the N steps thing and the capital T thing. So here is a bargain. And now I've got rid of the capital T. So now I'm going to assume that your time step is between 0 and 1. It basically represents what percentage of the way through the diffusion process. Are you? So 0 would be all noise and one would be, or those are the way we're at 0 would be all clean and one would be all noise. So what, how far through the forward diffusion process? So other than that, this is exactly the same equation we've already seen. And I realized something else which is kind of fun, which is you can take the inverse of that. So you can calculate T. So we would basically first take the square root. And we would then take the inverse cos. And we would then divide by 2 over pi or times pi over 2. So we can both. So it's interesting now we don't the the alpha bar is not something we look up in a list is something we calculate with a function from a float. And so yeah, interestingly, that means we can also calculate T from an alpha bar. So noise if I has changed a little. So now when we get the alpha bar through our time step, we don't look it up. We just call it all the function. And now the time step is a random float between 0 and 1. Actually, between 0 and 1.999, which actually, I'm sure there's a function. I could have chosen to do. A float in this range, but I just kept it because I was lazy. It couldn't be bothered to get up. Other than that, noise applies exactly the same. Right. So we're still returning the XT, the time step, which is now a float. And the noise, that's the thing we're going to try and predict. dependent variable, this tuple is our inputs model. Alright, so here is what that looks like. So now when we look at our input to our unit training process, you can see, you know, we've got a T of 0.05. So 5% of the way through the forward diffusion process. It looks like this and 65% through what looks like this. So now the time step and basically the process is more of a kind of a continuous time step and a continuous process. Rather, before we were having this discrete time steps here, we get it's just any band and value that could be between 0 and 1. I think that's also something. Wish got this more convenient, you know, to have, yeah, it is going to be just to have a function to call. Yeah, I find this life life, life a little bit easier. So the model is the same, the callbacks are the same, the fitting process is the same. And so something which is kind of fun is that we could now, again, when we do now create a little denoise function. So we can take, you know, this batch of data that we generated, the noise effect data to here it is again. And we can denoise it. So we know the T for each element, obviously. So remember T is different for each element now. And we can therefore calculate the alphabet for each element. And then we can just undo the noiseification to get the denoised version. And so if we do that is what we get. And so this is great, right? It shows you what actually happens when we run a single step of the model on very easily partially noise images. This is something you don't see very often because I guess not many people are working in these kind of interactive notebook environments where it's really easy to do this kind of thing. But I think this is really helpful to get a sense of like, okay, if you're 25% of the way through the forward diffusion process, this is what it looks like when you undo that. If you're 95% of the way through, this is what happens when you undo that. So you can see here it's basically like, oh, I don't really know what the hell's going on. So at least the noise E mess. Yeah, I guess my feeling from looking at this is I've impressed, you know, like this 45% noise thing. It looks all noise to me. It's found the long-sleeved top. And yeah, it's actually pretty close to the real one. I looked it up or what might say it later is a little bit more of a pattern here, but it even gives a sense of the pattern. So it shows you how impressive this is. So this is 35%. You can kind of see there's a shoe there, but it's really picked up the shoe nicely. So it's these are very impressive models in one step, in my opinion. So, okay, so sampling is basically the same, except now rather than creating a starting with using the range function to create a time steps, we're using Lin space to create our time steps. So at time steps start at, you know, if we did 1000, it would be 0.9999. And they end at zero, and then they're just linearly spaced with this number of steps. So other than that, you know, A bar we now calculate. And the next A bar is going to be whatever the current step is, minus one over steps. So if you're doing 100 steps, then you'd be minus 0.01. So this is just stepping through. Then yearly. And yeah, that's that's actually it for changes. So if we just do DDIM for 100 steps, you know, that works really well. We get a fit of three. Which is actually quite a bit better than we had on 100 steps for our previous DDIM. So this definitely seems like a good. Slampling, sampling approach. And I know Jono's going to talk a bit more shortly about, you know, some of the things that can make better sampling approaches, but yeah, definitely. We can see it making a difference here. Did you guys have anything you wanted to say about this before we move on? No, but it is a nice transition towards some of the other things we'll be looking at to start thinking about how do we frame this. And it's it's also good like the idea. So the original DDPM paper has this 1000 times that's in a lot of people follow that. And but the idea that you don't have to be bound to that and maybe it is worth breaking that convention. I know Tanish made that meme about, you know, this 15 computing different standards connotation. And but yeah, sometimes it's helpful to reframe it. Okay, time goes from zero to one that can simplify some things. Yeah, complicates out of this. But yeah, it's nice to think how you can reframe stuff. Yeah, and in fact, where we will have today by the time we get to know, 23, we will see. And you know, even simpler notation. And yeah, simpler notation generally comes. I think what happens is over time, people. Understand better what's the essence of the problem and the approach and then that gets reflected in the in the notation. So okay, so the next one I wanted to share is something which is an idea we've been working on for a while. Add it's some new research. So partly, I guess this is an interesting like insight into how we do research. So this is 22 noise. And the basic idea of this was, well, actually, I'm going to take you through it to see what the basic ideas. So what I'm going to do is I'm going to create, okay, so fashion, amnesty is before. Um, but I'm going to create a different kind of model. I'm not going to create a model that predicts the noise. Given the noise image and T instead, I'm going to try to create a model which predicts T given the noise image. So why did I want to do that? Well, partly, well, entirely, because I was curious. I felt like when I looked at something like this, I thought it was pretty obvious. Roughly how much noise each image had. And so I thought, why are we passing noise? What do we call the model? Why are we passing in the noise image and the amount of noise or the T? Given that I would have thought the model could figure out how much noise there is. So I wanted to check my contention, which is that the model could figure out how much noise there is. So I thought, okay, well, let's create a model that we're trying to figure out how much noise there is. So, um, so I created a different noise of phi now. And this noise of phi um, grabs an alpha bar T um, randomly. Um, and um, it's just a random number between zero and one, but you know, one per item in the batch. Um, and so then after just randomly grabbing an alpha bar T, where that noise of phi in the usual way, but now our independent variable is the noise image and the dependent variable is alpha bar T. And so we've got to try to create a model that can predict alpha bar T given a noise image. Um, okay, so everything else is the same as usual. And so we can exceed exam. You've got alpha bar T dot squeeze dot bloggit. Oh, yeah, that's true. So, um, the alpha bar T goes between 0 and 1. So we've got a choice like, I mean, we don't have to do anything, but you know, normally if you've got some between zero and 1, you might consider putting a sigmoid at the end of your model. But um, I felt like the difference between 0.9999 and 0.99 is very significant, you know, um, so if we do log it, then it, we don't need the sigmoid at the end anymore. It won't, you know, it will naturally cover the full range of kind of, you know, to be centered at zero. We're talking about, you know, the normal kind of range of numbers. And it also will treat, you know, equal ratios as equally important at both into the spectrum. So that was my hypothesis was that using log it would be better. I did test it and it was actually very dramatically better. So without this log it here, my model didn't work well at all. And so this is like an example of where thinking about these details is really important. Because if you had, if I hadn't have done this, then I would have come away from this bit of research thinking like, oh, I was wrong. We can't predict. Noise noise amount. Yeah, so thanks for pointing that out, China. Yeah, so that's why in this example of a mini batch, you can see that the numbers are can be negative or positive. So zero would represent noise alpha bar of 0.5. So here 3.05 is not very noise at all. Where else negative one is pretty noisy. So the idea is that, yeah, given this image, you would have to try to predict 3.05. So, um, so one thing I was kind of curious about is like it's always useful to know is like, what's the baseline? Like what counts as good. You know, because often people will say to me like, oh, I created a model and the MSC was 2.6. I'd be like, well, is that good? Well, it's best I can do. But is it good? Like, or is it is it better than random? Or is it better than predicting the average? So in this case, I was just like, okay, well, what if we just predicted? Actually, this is slightly out of date. I should have said zero here. Rather than zero point five, but never mind close enough. So this is before I did the log at thing. So I basically was looking at like, what's the, you know, loss if you just always predicted a constant. Which as a session of what zero here, um, have an updated it. Um, and so it's like, oh, that would give you a loss of 3.5. Uh, or another way to do it is you could just. Cap just put MSC here and then look at the MSC loss between point five and your various, uh, just a single mini batch, which we, yeah, any batch of alpha batteries, uh, logets. Um, yeah, so, you know, we wanted to get some, you know, if we're getting something that's about three, then we basically haven't done any better than, than random. Um, and so this case, this, this, this model. Um, it doesn't actually have anything to learn. It always returns the same thing. So we can just call fit with trade equals false just to find the loss. So this is just a couple of ways of getting quickly finding a loss for a baseline naive model. Um, one thing that thankfully I talked for a warn you about is if you try to use MSC. And your inputs and targets have different shapes. It will broadcast and give you probably not the results you would expect and it will give you a warning. So one way to avoid that is just to use dot flatten on each. Um, uh, so this kind of flattened MSC is useful to avoid both avoid the warning and also avoid getting weird errors. Or we're sorry, weird results. So we use that for our loss. So the models, the model that we always use. So it's kind of nice. We just use our same model. Nothing changes. Um, even though we're doing something totally different. Um, oh, wow, okay, that's not quite true. One difference is that our output. We just have one output now. Because this is now a regression model. It's just trying to predict a single number. And so our, um, learner now uses MSC is the loss. Um, everything else is the same as usual. So we could go ahead and trade it and you can see, okay, the loss is already much better than three. So we're definitely learning something. And we end up with a point 075. Um, mean squared error. That's pretty good considering, you know, there's a pretty wide range of numbers. We're trying to predict here. Um, so I'm going to, I'm going to save that as noise prediction on sigma. So save that model. And so we can take a look at how it's doing by grabbing our one batch of noise images, putting it through our T model. Actually, it's really an alpha bar model that never mind quality model. And then we can take a look to see what it's predicted for each one. Um, and we can compare it to the actual for each one. And so you can see here, it said, oh, I think this is about point 91. And actually it is point 91. So oh, here it looks like about point 36. And yeah, it is actually point 36. So you know, you can see overall point 72. It's actually point 72. Well, I was or exactly right. This one's point 0.02 off. But yeah, my hypothesis was correct, which is that, um, we, you know, we can predict the thing that we were putting in manually as input. So there's a couple of reasons I was interested in checking this out. The, you know, the first was just like, well, yeah, it wouldn't be simpler. If we weren't passing in the D each time, you know, why, why not not pass in the T each time. But it also felt like it would open up a wide range of kind of how we can do sampling. Um, the idea of doing sampling by like precisely controlling the amount of noise that you try to remove each time. And then assuming you remove exactly that amount of noise each time, feels limited to me. Um, so I, I, I want to try to remove this constraint. So having, yeah, built this model, I thought, okay, well, it, you know, which is basically like, okay, I think we don't need to pass T in. Let's try it. So what I then did is I replicated the 22 cosine notebook. I just copied it pasted it in here. Um, but I made a couple of changes. The first is that noiseify doesn't return T anymore. So there's no way to cheat. We don't know what T is. And so that means that the unit now doesn't have T. So it's actually going to pass zero every time. So it has no ability to learn from T because it doesn't get. So it's going to, it doesn't really matter what we pass in. We could have changed the unit to like remove the conditioning on T. But that for research, this is just as good, you know, for finding, for finding out. And it's good to be lazy when doing research. There's no point doing something a fancy way when you can do it a quick and easy way before you even know if it's going to work. Um, so yeah, that's the only change. So we can then train the model and we can check the loss. So the last year is point O34. And previously it was point O33. So interestingly, you know, maybe it's a tiny bit worse at that, you know, but it's very close. Um, okay, so we'll save that model. And then for sampling, I've got exactly the same DTIM step as usual. And by sampling is exactly the same as usual, except now when I call the model, I have no T to pass in. Um, so we just pass in this. I mean, I still know T because I'm still using the usual sampling approach, but I'm not passing it to the model. And yeah, we can sample and what happens is actually pretty garbage. 22 is our fit. And as you can see here, you know, some of the images are still really noisy. So I totally failed. And so that's always a little discouraging when you think something's going to work and it doesn't. But my reaction to that is like, if I think something's going to work and it doesn't is to think, well, I just going to have to do a better job of it. You know, I like it ought to work. So I tried something different, which is I thought like, okay, um, since it went up passing in the T. Then we're basically saying like, how much noise should you be removing? It doesn't know exactly. So I remove a little bit more noise that we want or a little bit less noise than we want. And we know from the, you know, testing we did, um, that sometimes it's out by like this case, 0.02. And I guess if you're out consistently, sometimes it's, yeah, I got to end up not removing all the noise. So the change I made was to the DDIM step, um, which is here. And, uh, let me just copy this and get rid of the, I'm into that section. It's just to make it a bit easier to read. Okay. So the DDIM step, this is the normal DDIM step. Okay. And so step one is the same. So don't worry about that. It's the same as we've seen before. But what I did was I actually used my T model. So I passed the noise image into my T model, which is actually an alpha bar model to get the predicted alpha bar. And this is remember the predicted alpha bar for each image, because we know from here that sometimes, so sometimes it's a pretty good job. Right. But sometimes it didn't. So I felt like, okay, we did a predicted alpha bar for each image. Um, what I then discovered is, um, sometimes that could be like really too low. Right. So what I wanted to make sure it wasn't too crazy. So I then found the median for a mini batch of all the predicted alpha bars. And I clamped it to not be too far away from the median. Um, and so then what I did when I did my X naught hat is rather than using alpha bar T, I used the estimated alpha bar T for each image, clamped to be not too far away from the median. And so this way it was updating it based on the amount of noise that actually seems to be left behind, rather than the assumed amount of noise that should be left behind, you know, if we assume it's removed the correct amount. Um, and then everything else is the same. So when I did that, so well, made all the difference. And here it is. They are beautiful pieces of clothing. So 3.88 versus 3.2. That's possibly close enough like I'd have to run it a few times, you know. My guess is maybe it's a tiny bit worse, but it's pretty close. But like this definitely gives me some encouragement that, you know, even though this is like something I just did in a couple of days, where else they're kind of the with T approaches have been developed since 2015 and we're now in 2023. I would expect it's quite likely that these kind of like no, no T approaches could eventually surpass the T based approaches. And like one thing that definitely makes me think is our interim proof is if I plot the the third or the kid, or each sample during the reverse diffusion process, it actually gets worse for a while. I'm like, okay, well, that's, that's a bad sign. I have no idea whether it's happening, but it's a sign that if we could improve each step, then one would assume we could get better than 3.8. Yeah, tonight's coach, I know how many thoughts about that or questions or comments or. And maybe to just like to highlight that the research process a little bit, it wasn't like this linear thing of like, oh, here's this issue not for me as well as we bought. Oh, here's the fix we just kept this. So you know, this was like multiple days of like discussing and like Jeremy saying, like, you know, I'm telling my hair out, you guys have any ideas and what about this and oh, I noticed in the team paper, they do this camping, maybe that'll help. You know, so there's a lot of back at fourth and also a lot of like you saw that code there was commented out there, prints xt.min, xt.max, alpha bar, you know, just like seeing, oh, okay, you know, my average prediction is about what I expect, but sometimes the middle of the max goes, you know, two, three, eight, 16, 150, 12 million, infinity, you know, if you like one or two little values that would just skyrocket out. Yeah, and so that kind of like, debugging and exploring and printing the results. And actually, our initial discussions about this idea, I kind of said to you guys before or less than one of part two, I said, like it feels to me like we shouldn't need to T thing and so it's actually paint like, you know, I'm gonna like away in the background for months. Yeah, yeah. And I guess, I mean, we should also mention we have tried this like a friend of us trained a no T version of disabled fusion for us and we did the same sort of thing I trained a pretty bad T predictor in it sort of generate samples. So we're not like focusing on that large scale stuff yet, but it is fun to like every not again got this idea from fashion in this. We are trying these out on some bigger models and seeing, okay, this does seem like maybe it'll work. And to done the line that future plan is to say that it's actually, you know, spend the time training proper model and see, yeah, see how well that does if it's interesting. You say a friend of ours, we can be more specific. It's Robert one of the two lead authors of the stable diffusion paper who yeah actually has been fine tuning a real stable diffusion model, which is without T and it's looking super encouraging. So yeah, that'll be fun to play with with this new, we don't have to train a T predictor for that. See how it looks. Yep. All right. So I guess the other area we've been talking about kind of doing some research on is this weird thing that came up over the last two weeks where our bug in the DDP implementation where we accidentally weren't doing it from minus one to one for the input range. It turned out that actually being from minus one to one wasn't a very good idea. Anyway. And so we ended up centering it as being and from minus point five to point five. And John O and Tuniski have managed to actually find a paper. Well, I see find a paper. Paper has come out in the last 24 hours, which has coincidentally cast some light on this. And there's also a size of a paper that we weren't aware of, which was not released in the last 24 hours. So John, are you going to tell us a bit about that? Yeah, and I sure I can do that. So it's funny. This was such perfect timing because I actually got up early this morning planning to run with the different input scaleings and the cosine schedule that Jeremy was showing in some of the other schedule as we look at. I thought it might be nice for the lesson to have a little plot of like what is the fit with these different salt as an input scaleings, but it was going to be a lot of work. Not looking forward to doing the groundwork and the internet certainly this paper, which AK had just tweeted out because he reviews anything that comes up on archive every day on the importance of noise scheduling for diffusion models. And this is by a researcher at the Google Brain team who's also done a really cool recent paper on something called a recurrent interface network outside of the script of this lesson, but also with checking out. Yeah, so this paper they're referring to study. There's noise scheduling and the strategies that you take for that and they want to show that number one, those scheduling is crucial for performance and the optimal one depends on the types. When increasingly image size the noise scheduling that you want changes and scaling the input data by some factor is a good strategy for for working with this. And that's the big big deal here, right? Yeah, that's what we've been doing where we said, oh, do we scale from minus point five to five or minus one to one or do we normalize. And so they demonstrate the effectiveness by training a really good high resolution model on image met so class condition model. Yeah, amazing. So they'll show one later. So really like this paper, it's very like short and concise and it just gets all the information across. And so they introduced us here, we have this noise in process on noise five function where we have square root of something times X, the spirit of one minus that something times the noise. And then we use gamma gamma of T, which is often used for the continuous time case. So instead of the alpha bar and the beta bar schedule for a thousand times, there will be some function gamma of T that tells you what your alpha bar should. Okay, so that's how for our function is actually called a bar, but it's the same thing. Yeah, same thing takes in a time set from zero to one. And then that's used to noise the image. Interestingly, what they're showing here actually is something that we had discovered and I'd been complaining about that. I D T I M's with an eater of less than one what working, which is to say when I added extra noise to the image. It wasn't working. And what they're showing here is like, oh yeah, duh, if you use a small image, then adding extra noise is probably not a good idea. Yeah. And so they they use a lot of reference in this paper to like information, be destroyed and signal to noise ratios. And that's really helpful for thinking about because it's not something that's obvious, but at 64 by 64 pixels adjacent pixels might have much less in common. This is the same amount of noise added at a much higher resolution. The noise kind of averages out and you can still see a lot of the image. So yeah, that's one thing they highlight is that the same noise level for different image sizes might have it. It might be a harder or easier times. And so they investigate some strategies for this. They look at the different noise schedule functions. So we've seen the original version from the DDGM paper. The cosine schedule at we've seen. I think we might look at all the next thing that Jamie's going to show us a sigmoid based schedule. And so they show the continuous time versions of that and they plot how you can change various parameters to get these different. And the functions or in our case, the alpha bar, we're restarting at all and image no noise at t equals zero moving to all noise no image at t equals one. But the path that you take and it's going to be different for these different classes of functions and parameters. And the signal to noise ratio, that's what this or the log signal to noise ratio is going to change over that time as well. And so that's one of the knobs we can tweak me saying our diffusion model is a training that well, we think it might be related to the noise schedule and so on. One of the things you can do is try different noise schedules either changing the parameters in one class of noise schedule or switching from other near to a cosine to a sigmoid. And I mean the second strategy is kind of what we were doing in those experiments, which is just to add some scaling factor to X there. Well, we're absolutely dark. Well, yeah, well, we were accidentally using you be of 0.5. Exactly. And so that's a second dial that you can tweak is to say keeping your noise schedule fixed, maybe you just scale X zero, which is going to change the ratio of signal to noise. And that's what I think is for in C there is what we were accidentally doing. Yes, yeah, it's that king. And so see if we can get to. Oh, yeah, so that again changes the signal to noise for different scaling is you get. And so let's find so they have a compound, they have a strategy that combined some of those things. And this is the important part they do their experiments. And so they have a nice table of investigating different schedules, cosine schedules and sigmoid schedules. And in bolder, the best results and you can see for 64 by 64 images, versus 128 to the 76. The best schedule is not necessarily always the same. And so that's like important finding number one, depending on what your data looks like using a different number schedule might be optimal. There's no one true best schedule. There's no one value of you know, beta min and beta max that's just magically the best. And likewise for this input scaling at different sizes. With whatever schedules they tested and different values were kind of optimal. And so yeah, it's just a really great illustration, I guess, that this is another design choice that's implicit or explicitly part of your diffusion model training and sampling is how are you dealing with this. There's no schedule what what schedule I'm following what scaling are you doing a good inputs. And by using this thinking of doing these experiments and they come up with a kind of rule of thumb for how to scale the image based on image size. They show that they can as they increase the resolution, they can still maintain really good performance. And we're previously quite hard to train a really large resolution pixel space model. And they're able to do that they get some advantage from their fancy recurrent interface network. But still. And it's kind of cool that they can say look, we get state of the art, high quality and five and 12 by five and call one or two four, that one or two four. And saddles on class English and image net and using this approach to really like consider how all do train how many steps do we need to take one of the other things in this table is that they compare to previous approaches. Oh, we used you know, a third of the training steps and for the same other settings and we get better performance. And just because we've chosen that input scaling better. And yeah, so that's the paper really, really nice great work to the team. And that was right. I also got up in the morning and thought, it's going to be a hassle training all these different models. I need to train for different input scaling and different sampling approaches. I just look at Twitter first and then you looked at Twitter and there was a lot. And there was a paper saying like, hey, we just did a bunch of experiments for different always schedules and input scaling. Yeah, it's your wife always work that way. Try that. It seems quite blessed. It's yeah, it's very lucky like that. Yeah. If you wait long enough, something else will do it. That's why it's so is that the time of the case starts posting a Twitter. It's like my favorite hour of the day. For all the neighbors to be posted. Well, thank you for that. And so. So let me switch to notebook 23. Because this notebook is actually largely an implementation of some ideas from this paper that everybody tends to just call us. Because there's other people. But I will do it anyway. Carous paper. And the reason we're going to look at this is because in this paper, the authors actually take a much more explicit look at the question of input scaling. The approach was not apparently to accidentally put it back in their code and then take it out and find it worth worse and then just put it back in again. The approach was actually to think how should things be. So that's an interesting approach to doing things and I guess it works with them. So that's fine. I think our smog is more inflady. Exactly. Our approach is much more fun because you never quite know what's going to happen. And so yeah, in their approach they actually tried to say like, okay, given all the things that are coming into our model, how can we have them all nicely balanced. So we will skip back and forth between the notebook and the paper. So the start of this is all the same except now we are actually going to do it minus one to one because we're not going to rely on accidental bugs anymore, but instead we're going to rely on the carousers papers carefully designed. Staling. I say that except that I put a bug in the is no book as well. What are the things that's in the carous paper is what is the standard deviation of the actual data which I calculated for a batch. However, this used to say minus 0.5. I used to do the minus 0.5.5 thing. And so this is actually the standard deviation of the data before I before when it was still minus 0.5. So this is actually half the real standard deviation. For reasons I don't yet understand this is giving me better scaled results. So this actually should be 0.66. So there's still a bug here and the bug still seems to work better. So we still got some mysteries involved. So we're going to leave this. So it's actually yeah, it's actually not 0.33. It's actually 0.66. Okay, so the basic idea of this bug actually I'll come back. Well, you have a little thing. Yeah, okay, now let's start here. The basic idea of this paper is to say, you know what? Sometimes maybe predicting the noise is a bad idea. So like you can either try and predict the noise or you can try and predict the clean image and each of those can be a better idea in different situations. If you're given something which is nearly pure noise, you know, the models given something which is nearly pure noise. And is then asked to predict the noise. That's basically a waste of time because all things noise. If you do the opposite is you try to get it predict the clean image. Well, then if you give it a plate image that's nearly clean and try to predict the plate image, that's nearly a waste of time as well. So you want something which is like regardless of how noisy the image is, you want it to be kind of like an equally difficult problem to solve. And so what caros do is they basically use this new thing called C skip, which is a number, which is basically saying like, you know what we should do for the training target. It's not just predict the noise all the time. Not just predict the clean image all the time, but predict and a alert version of one or the other depending on how noisy it is. So here, why is the plane image and N is the noise. So Y plus N is the noise image. And so if C skip was zero, then we would be predicting the clean image. And if C skip was one, we would be predicting Y minus Y. We would be predicting the noise. And so you can decide by picking a different C skip, whether you're predicting the clean image or the noise. And so as you can see from where they've written that they make this a function, they make it a function of sigma. Now this is where we've got to a point now where we've kind of got a fairly, a much simpler notation. There's no more alpha bars, no more alphas, no more beaters, no more beta bars. This is just a single thing called sigma. Unfortunately, sigma is the same thing as alpha bar used to be. Right. So we've simplified it, but we've also made things more confusing by using existing symbol for something totally different. So this is alpha bar. Okay. So there's going to be a function that says depending on how much noise there is, well, either predict the noise or we'll predict the clean image or we'll predict something between the two. So in the paper, they showed this chart where they basically said like, okay, let's look at the loss to see how good are we with a trained model at predicting when sigma is really low. So when there's very small alpha bar or when sigma is in the middle or when sigma is really high. And they basically said, you know what, when it's nearly all noise or nearly no noise, you know, we're basically not able to do anything at all. You know, we're basically good at doing things when there's a medium amount of noise. So when deciding, okay, what, what signals are we going to send to this thing? The first thing we need to do is to is to figure out some signals. And they said, okay, well, let's pick a distribution of signals that matches this red curve here. As you can see. And so this is a normally distributed curve where this is on a log scale. So this is actually a log normal curve. So to get the signals that they're going to use, they picked a normally distributed random number. And then they expect it. And this is called a log normal distribution. And so they used a mean of minus 1.2. And a standard deviation of 1.2. So that means that about one third of the time, they're going to be getting a number that's bigger than zero here. And e to the zero is 1. So about 1 third of the time, they're going to be picking signals that are bigger than 1. And so here's a histogram, I drew, of the signals that we're going to be using. And so it's nearly always less than 5. But sometimes it's way out here. And so it's quite hard to read these histograms. So this really nice library called seaborn, which is built on top of Matplotlib, has some more sophisticated and often nicer looking plots. And one of them they have is called a KDE plot, which is a kernel density plot. It's a histogram, but it's smooth. And so I clicked it at 10 so that you could see it better. So you can basically see that the vast majority of the time it's going to be somewhere, you know, about 0.4 or 0.5. But sometimes it's going to be really big. So our noise if I is going to pick a sigma using that locked on more distribution. And then we're going to get the noises usual. But now we're going to calculate C skip, right? Because we're going to do that thing we just saw. We're going to find something between the plane image and the noise input. So what do we use for C skip? We calculate it here. And so what we do is we say, what's the total amount of variance at some level of sigma? Well, it's going to be sigma squared. That's the definition of the variance of the noise. But we also have the sigma of the data itself. Right? So if we add those two together, we'll get the total variance. And so what the carous paper said to do is to do the variance of the data divided by the total variance and use that for C skip. So that means that if your total variance is really big, so in other words, it's got a lot of noise. Then C skip is going to be really small. So if you've got a lot of noise, then this bit here will be really small. So that means if there's a lot of noise, try to predict the original image. Right? That makes sense because predicting the noise would be too easy. If there's hardly any noise, then this will be total variance will be really small. Right? So C skip will be really big. And so if there's a lot of if there's hardly any noise, then try to predict the noise. And so that's basically what this C skip does. So it's a kind of slightly weird idea is that our the target, the thing we're trying to do actually is not the input image. Sorry, the original image. It's not the noise, but it's somewhere between the two. And I found the easiest way to understand that is to draw a picture of it. So here is some examples of noise input, right? With various amounts of with various signals. Remember, sigma is alpha bar. Right? So here's an example with very little noise, 0.06. And so in this case, the target is predict the noise. Right? So that's the hard thing to do. This predict the noise. Where else? Here's an example, 4.53, which is nearly all noise. So for nearly all noise, the target is predict the image. Right? And then for something, which is a little bit between the two, like here, 0.64, the target is predict some of the noise and some of the image. So that's the idea of Paris. And so what this does is it's making the problem to be solved by the unit. Equally difficult regardless of what sigma is. It doesn't solve our input scaling problem. It solves our kind of difficulty scaling problem to solve the input scaling problem. They do it. I just want to make one quick note. And so like this sort of idea of I can also interpolating between the noise and the image is similar to what's called the VM objectives as well. So there's also a similar kind of it's yeah, it's really quite similar to what the character does, but that's also not been used in a lot of different models. Like, for example, a steeple diffusion to point out was trained with this sort of be objective. So people are using this sort of the sort of methodology and getting good results. And yeah, so it's it's an actual practical thing that people are doing. So yeah, just make a note of that. Yeah, as is the case of basically all papers created by Nvidia researchers of which this is one it flies under the radar and everybody knows it. The V objective paper came from the senior author was Jim Salamons, which is Google, right. Yeah, and so anything from Google and open AI everybody listens to. So, you know, the carus I think has done the more complete version of this. And in fact, the V objective in was almost like mentioned impassion in the distillation paper. But yeah, that's the one that everybody has that I'm looking at. But I think this is the more. Yeah, I think what happened with the V objective is not many people paid attention to it. I think folks like cat and raw data, these sorts of folks are actually paying attention to that V objective in that Google brain paper. So, but then also this paper did a much more principled analysis of this sort of thing. So yeah, I think it's very interesting out. Yeah, sometimes even these sort of side notes in papers that maybe people don't pay much attention to it can actually be quite important. Yeah, yeah. So, okay. So the noise import as usual is the input image plus the noise times the sigma. But then, and then as we discussed, we decide how to kind of decide what what our target is. But then we actually take that noise input and we scale it up or down by this number. And the target we also scale up or down by this number. And those are both calculated in this thing as well. So here's see out. And here's see in now I just wanted to show one example of where these numbers come from because for a while they also in pretty mysterious to me and I felt like I'd never based on enough to understand them. Particularly because they're explained in the mathematical appendix of this paper which erodes the bits I don't understand. And until I actually try to and then it tends to turn out they're not so bad after all, which was certainly case here. Um, which I think it was up it was be something I think. Be so that be B6 I think that the one. Oh yeah. So it appendix B6 which does look pretty terrifying. But if you actually look at for example what we're just looking at see in. It's like how do they calculate so see in is this now this is the variance of the noise. This is the variance of the data at them together to get the total variance square roots the standard deviation total standard deviation. So it's just the inverse of the total standard deviation which is what we have here where does that come from well they just said you know what. The inputs for a model should have unit variance. Now we know that we've we've done that to dare in this course. So they said we're right. So well the inputs to the model is the the clean data plus the noise times some number we're going to calculate and we want that to be one. Okay so the variance of the clean images plus the noise is equal to the variance of the clean images plus the variance of the noise. Okay so if we want that to be if we want variance to be one then divide both sides by this and take the square root. And that tells us our multiplier has to be one over this. That's it. So it's like literally you know classical math. The only bit you have to know is that the variance of two things added together is the variance of the two things added together which is not rocket science either. And this context like why we want to do this when we looked at those segments that you're putting like the distribution you've got some that are fairly low but you've also got some way to standard deviation. Sigma is like 40 right so the variance is super high. Yes. And so we don't want to feed something with standard deviation 40 into our model you would like it to be closer to unit variance. So we're thinking okay well if you divide by roughly 40 that would get it down but then we've also got some extra variance from our data. So it's like exactly. What do you plus the data of a little books we want to you know scale back down by that to get unit variance. Yeah I mean I love this paper because it's basically just doing what we spent weeks doing of like I feel like everything that we've done that's improved every model has always been one thing which is can we get. So that means zero variance one inputs to our model and for all of our activations and and then the other thing is our include enough compute by adding enough layers and enough activations those two things seem to be all that matters. Well I guess resnits added an extra call little thing to that which is to make it a you know make it. Even smoother by giving us kind of like identity path. So yeah basically trying to make things as. Smooth as possible and as as equal everywhere as possible. So yeah this is what they've done so they did that for the inputs and then they've also done it. For the outputs and for the outputs you know it's basically. The same idea you know they have basically the same kind of analysis to show that. And so with this. So now yeah we basically we've got a noise input. We've got the you know kind of linear version somewhere between X naught and the noise input. We've got the scaling of the output and we've got the scaling of the input. So now for the inputs to our model we're going to have the scaled noise. We're going to have the sigma. And we're going to have the target which is somewhere between the image and the noise. And so yeah so I've. You know never seen anybody draw a picture of this before so it's really cool when you know being in a notebook being able to see like oh that's what they're doing. You know so yeah have a good look at this notebook to see exactly what's going on because I think it's really good intuition around what problem it's trying to solve. So then I actually checked the noise input has a standard deviation of one. It means not zero and of course by would it be we didn't do anything you know the only thing carous cared about was having the variance one. We could easily adjust the input and output to have a mean of zero as well and that's something I think we or somebody should try. Because I think it does seem to help a bit as we saw with that generalized values stuff we did. But it's less important than the variance and so same with the target that's got the one. And yeah this is where if I change this to the correct value which is 0.66 then actually it's slightly further away from one. Both here and here quite a lot further away and maybe that's because actually the data's well we know the data's not Gaussian distributed pixel data definitely isn't Gaussian distributed so. This bug turned out better. So the units are same the initializations the same this is all the same train it for a while we can't compare the losses right because our target's different so. But what we can do is we can create a denoise that just takes the thing that as per usual the thing we had a noisify right and so for X naught so we got a model play by C out and then add C skip by noise to. Here it is model play by C out at noise to. Okay so we can do noise so. Let's grab our. Let's calculate C skip C out and see in or the signals in our mini batch let's use the model to predict the target given the dyes to input and the signals and then denoise it. And so here's our noise to input which we've already seen and here's our predictions and these are absolutely remarkable in my opinion. Yeah like this one here I can barely see it you know it's really found it's a lot look at the shirt there's a shirt here it's actually really finding the little thing on the front and let me show you here's that what it should look like. And in cases where the sequence pretty high like here you can see it's really like saying like I don't know maybe it's shoes but it could be something else. Is it shoes yeah it wasn't shoes but it's just kind of got the you know the bulk of the pixels in the right spot. Yeah something like this one is 4.5 has no idea what it is it's like oh maybe it's shoes maybe it's pants you know turn that it is shoes. Yeah so I think that's fascinating how well it can do. And the other thing I did which I thought was fun was I just created so I just did a sigma of 80 which is actually what they do when they're doing sampling from pure noise that's that's what they're considered the pure noise level. So I just created some pure noise and denoise it just for one step and so here's what happens when you denoise it for one step and you can see it's kind of overlaid all the possibilities. Like I can see a pair of shoes here a pair of pants here top here and sometimes it's kind of like more confident that the noise is actually a pair of pants and sometimes it's more confident that it's actually shoes. They can really get a sense of how like from pure noise it starts to make a call about like what this noise is actually covering up. And this is also the bit which I feel is like I'm the least convinced about when it comes to diffusion models this this first step of going from like pure noise to something and like trying to have a good mix of all the possible some things I'm I don't know it feels a bit hand wavy to me it clearly works quite well but I'm not sure if it's like we're getting the full range of possibilities and I feel like some of the papers we're starting to see it's starting to say like you know what maybe this is not quite the right approach. And then maybe later in the course we'll look at some of the ones that look at what we call VQ models and tokenized stuff. Anyway, I thought this is pretty interesting to see these pictures which I don't think. Yeah, I've never seen any pictures like this before so I think this is a fun result from doing all this stuff in notebooks step by step. Okay, so sampling. So one of the nice things with this is a sampling becomes much much much simpler. And so and I should mention a lot of the. Oh, that I'm using particularly in a sampling section is heavily inspired by and some of it's actually copied and pasted from cats K diffusion repo, which is I think I mentioned before is some of the nicest. Generative modeling code or maybe the nicest generative modeling code of ever seen. It's really great. So before we talk about the actual sampling, the first thing we need to talk about is what sigma do we use at each reverse time step. And in the past we've always what nearly always done something which I think has always felt is sketchy as all hell, which is we've just linearly gone down the sigma's or the alpha bars or the T's. So here when we're sampling in the previous notebook, we used Lin space. So I always felt like that was questionable and I felt like at the start, you probably like it was just noise anyway. So who cared who cares. So I indeed PM V3 experimented with something that I thought intuitively made more sense. I don't know if you remember this one, but I actually said, oh, let's for the first hundred times depths, let's actually only run the model every 10 times and then for the next hundred let's run it nine times the next one hundred let's run it every eight times. So basically at the start, be much less careful. So carus actually ran a whole bunch of experiments and they said, yeah, you know what, at the start of training, you know, you can start with a high sigma, but then like step to a much lower sigma in the next step and then a much lower sigma in the next step. And then the longer as the more you train step by smaller and smaller steps. So that you spend a lot more time fine tuning carefully at the end and not very much time at the start. Now this has its own problems. And in fact, a paper just came out today, which we probably won't talk about today, but maybe another time which talked about the problems is that in these very early steps, this is the bit where you're trying to create a composition that makes sense. Dale for fashion, endless, we don't have much composing to do. It's just a piece of clothing, but if you're trying to do an astronaut riding a horse, you know, you're going to think about how all those pieces fit together. And this is where that happens. And so I do worry that with the carus approach is what's not giving that maybe enough time. But as I said, that's really the same as this step at that whole piece feels a bit wrong to me. But aside from that, I think this makes a lot of sense, which is that, yeah, the sampling you should jump, you know, by big steps early on and small steps later on and make sure that the fine details are just so. So that's what this function does. Is it creates this lot? Now it's this, this, this schedule of, of reverse diffusion sigma steps. It's a bit of a weird function and that it's the, the growth route of sigma where row is seven. So the seven through of sigma is basically what it's scaling on. But the answer to why it's that is because they tried it and it turned out to work pretty well. Do you guys remember where this was? This is a truncation error analysis, D, D1. That's very. So, this image here. So thanks for to me to remind me where this is shows fed as a function of row. So it's basically what? The what's root are we taking? And they basically say it said like if you take the fifth root up, it seems to work. What basically? So, yeah, so that's a perfectly good way to do things is just to try things and see what works. And you'll notice they tried things just like we love on small data sets, not as small as us. Because we're the king of small data sets, but small is just like far 10 image net 64. That's the way to do things. So I saw like. I might have even been the CEO of hugging face the other day, treat something saying only people with huge amounts of GPUs can do research now. And I think it totally misunderstands how research has done, which is research has done on very small data sets. That's that's the actual research. And then when you're all done, you've stayed up at the end. I think we're kind of pushing the envelope in terms of like, yeah, how much can you do? And yeah, we've like re covered this kind of main substantive path of diffusion models history step by step, showing every improvement and seeing clear improvements across all the papers using nothing but fashion amnest running on a single GPU in like 15 minutes of training or something per model. So, yeah, definitely don't need lots of models. Anyway, okay, so this is the sigma we're going to jump to. So the denoising is going to involve calculating the C skip C out and C in and calling our model with the C in scale data and the sigma and then scaling it with C out and then doing the C skip. Okay, so that's just undoing the noise of fire. So check this out. This is all that's required to do one step of denoising for the simplest kind of scheduler, which is sorry, the simplest kind of sample, which is called oiler. So we basically say, okay, what's the sigma at time step I? What's the sigma to at time step I? And now when I'm talking about time step, I'm really talking about like the step from this function. So this is this is a horizontal bit of sampling step. Yeah. Okay, so then denoise using the function and then we say, okay, well, just send back whatever you were given. Plus move a little bit in the direction of the denoised image. So the direction is x minus denoised. So that's the noise that's the gradient as we discussed right back in the first lesson of this part. So we'll take the noise. If we divide it by sigma, we get a slope. It's how much noise is there per sigma. And then the amount that we're stepping is sigma to minus sigma one. So take that slope and multiply it by the change. Right? So that's the distance to travel towards the noise for this fraction. You know, all you could also think of it this way. I know this is a very obvious algebraic change, but if we move this over here, you could also think of this as being, oh, of the total amount of noise, the change in sigma we're doing, what percentage is that? Okay, well, that's the amount we should step. So there's two ways of thinking about the same thing. So again, this is just, you know, high school math. Well, I mean, actually, my seven-year-old daughter's done all these things. It's plus minus divide and times. So we're going to need to do this once per sampling step. So here's a thing called sample, which does that. It's going to go through each sampling step, call our sampler, which initially we're going to do sample Euler, right? With that information, add it to our list of results and do it again. So that's it. That's all the sampling is. And of course, we need to grab our list of sigma's to start with. So I think that's pretty cool. And at the very start, we need to create our pure noise image. And so the amount of noise we start with is got a sigma of 80. Okay, so if we call sample using sample Euler, then we get back some very nice looking images. And believe it or not, our Fed is 1.98. So this extremely simple sampler, three lines of code, plus a loop, has given us a Fed of 1.98, which is clearly, yet substantially better than our coastline. Now, we can improve it from there. So one potential improvement is to, you might have noticed, we added no new noise at all, right? This is a deterministic scheduler, right? There's no Rand anywhere here. So we can do something called an ancestral Euler sampler, which does add Rand. Right? So we basically do the denoising in the usual way, but then we also add some Rand. And so what we do need to make sure is given that we're adding a certain amount of Rand on this, we need to remove that amount of Rand on this from the step that we take. So I will go into the details, but basically there's a way, you know, our way of calculating how much new Rand on this, and how much just going back in the existing direction, do we do? And so there's the amount in the existing direction, and there's the amount in the new Rand on direction, and you can just pass in eta, which is just going to, when we pass it into here, is going to scale that. So if we scale it by half, so basically half of it is new noise, and half of it is going in the direction that we saw we should go, that makes it better still. Again, with 100 steps, and just make sure I'm comparing to the same, yep, 100 steps, okay, so that's fair, like with like. Okay, so that's adding a bit of extra noise. Now then, something that I think we might have mentioned back in the first lesson of this part, is something called Huns method. And Huns method does something which we can pictorially see here to decide where to go, which is basically we say, okay, where are we right now? What's the, you know, at our current point, what's the direction? So we take the tangent line, the slope, right? That's basically all it does is it takes a slope. So it's not here's a slope, you know? Okay, and so, if we take that slope, and that would take us to a new spot, and then at that new spot, we can then calculate a slope at the new spot as well. And at the new spot, the slope is something else. So that's it here, and then you say like, okay, well let's go halfway between the two. And that's actually follow that line. And so basically it's saying like, okay, each of these slopes is going to be inaccurate, but what we could do is calculate the slope of where we are, the slope of where we're going, and then go halfway between the two. It's, I actually find it easier to look at in code personally. I just could delete a whole bunch of stuff that's totally irrelevant to this conversation. So take a look at this compared to Euler. So here's our Euler, right? So we're going to do the same first line exactly the same. All right? Then the denoising is exactly the same. All right? And then the, this step here is exactly the same. I've actually just done it in multiple steps for no particular reason. And then it say, okay, well, if this is the last step, then we're done. So actually the last step is Euler. But then, what we do is we then say, well, that's okay for an Euler step, and this is where we'd go. Well, what does that look like if we denoise it? So this calls the model the second time, right? And where would that take us if we took an Euler step there? And so here, if we took an Euler step there, what's the slope? And so what we then do is we say, oh, okay, well, it's just, just like in the picture, let's take the average. Okay, so let's take the average, and then use that, the step. So that's all the Hewne sampler does. This is just take the average of the slope where we're at and the slope where the Euler method would have taken us. And so if we, now, so notice that it called the model twice, for a single step. So to be fair, since we've been taking 100 steps with Euler, we should take 50 steps with Hewne. Right? Because it's going to call the model twice. And still, that is now, whoa, we beat one. Which is pretty amazing. And so we could keep going. Check this out. We could even go down to 20. This is actually doing 40 model evaluations, and this is better than our best Euler. Which is pretty crazy. Now, something which you might have noticed is kind of weird about this, or kind of silly about this, is where cat, we're calling the model twice just in order to average them. But we already have two model results. Like without calling it twice, we could have just looked at the previous time step. And so something called the LMS sampler does that instead. And so the LMS sampler, I call it with 20, it actually literally does 20 evaluations. And actually it beats Euler with 100 evaluations. And so LMS, I work out at the details too much. It didn't actually fit into my little sampling very well. So basically, I actually copied and posted the cat's code. But the key thing it does is look, it gets the current sig, TIGMA, it does the denoising, it calculates the slope, and it stores the slope in a list. Right? And then it grabs the data. It grabs the first one from the list. So it's kind of keeping a list of up to, in this case, four at a time. And so it then uses up to the last four to basically, yes, out of the curvature of this and take the next step. So that's pretty smart. Yeah. So, I think if you wanted to do super fast sampling, it seems like a pretty good way to do it. And I think, John, you're telling me that, well, maybe it was Petra who was saying, that currently people have started to move away. This was very popular, but people started to move towards a new sampler, which is a bit similar to the DDPM+ sampler. Yeah. Yeah. Yeah. Yeah. But I think it's the same idea. I think it kind of keeps a, a list of recent results and use that. I'll have to check it more closely. Well, that's a good word. Yeah. That's similar idea. It's like, if it's done more than one step, then it's using some history to the next thing. Yeah. This is history. Anything doesn't make a huge sense, I guess, from that perspective. I mean, still works very well. This makes more sense. So then, you know, we can compare if we use an actual many batch of data. We get about 0.5. So, yeah, I feel like this is quite a stunning result. To get close to, very close to real data, this in terms of fit, you know, really with 40 model evaluations. And the entire, you know, the, you know, the, nearly the entire thing here is by making sure we've got unit variance, inputs, unit variance, outputs, and kind of equally difficult problems to solve in our loss function. Yeah. Plus having that different schedule for sampling. That's completely unrelated to the training schedule. I think that was one of the big things with caracetals. Paper was, they also could apply this to like, oh, existing diffusion models that have been trained by other papers. We can use our sampler and then fewer steps get better results without any of the other changes. And, and yeah, I mean, they do a little bit of rearraging equations to get the other papers versions into their C-SKIPC-NC-AX framework. But then, yeah, it's really nice that these ideas can be applied to. So for example, I think stable diffusion, especially version one, was trained, DDPM style training, epsilon objective, whenever. But you can now get these different samplers and different sometimes schedules and things like that and use that to sample it. And I do it in M15, 20 steps and get pretty nice samples. Yeah, you know, and another nice thing about this paper is they, you know, in fact, it's the name of the paper, elucidating the design space of diffusion based models. You know, there are up to various different papers and approaches and trying to say, like, oh, you know what? These are all doing the same thing when we kind of arameterize things in this way. And if you fill in these parameters, you get this paper and these parameters, you get that paper, you know, and then so we found a better set of parameters, which was very nice to code because, you know, it really actually ended up simplifying things a whole lot. And so if you look through the notebook carefully, which I hope everybody will, you'll see, you know, that the code is really there and simple compared to all the previous ones in my opinion. Like, I feel like every notebook we've done from DDPM onwards, the code's got easier to understand. And the results are just so quickly. And we're just going to clarify like how this connects with some of the previous papers that we looked at. Also like, for example, with the DDIM, the deterministic, that's again, this sort of deterministic approach that's similar to the Weiler-Met did, sampler that we were just looking at, which was completely deterministic. And then some of something like the Weiler ancestral that we were looking at is similar to the standard DDPM approach with the, that was kind of a more stochastic approach. So again, there's just all the sorts of connections that are kind of nice to see, again, the sorts of connections between the different papers and how they change it, how they can be expressed in this common framework. Yeah. Next, Tanishq. So we definitely now are at the point where we can show you the unit next time. And so I think we're, unless any of us come up with interesting new insights on the unconditional diffusion sampling, training and sampling process, we might be putting that aside for a while. And instead, we're going to be looking at creating a good quantity unit from scratch. And we're going to look at a different data set to do that. This was starting to scale things up a bit, as John mentioned in the last lesson. So we're going to be using a 64 by 64 pixel image net subset called tiny image net. So we'll start looking at some three channel images. So I'm sure we're all sick of looking at black and white shoes. So now we get to look at Swift dwellings and trolley buses and koala bears. And yeah, 200 different things. So that'll be nice. Yeah, all right. Well, thank you, Johno. Thank you, Tanishq. That was fun, as always. And yeah, next time we'll be less than 22. Bye. This was less than 22. Oh, no way. Okay. You're right. Okay. See ya. Bye-bye.
